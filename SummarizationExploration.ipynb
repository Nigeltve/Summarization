{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nigel\\anaconda3\\envs\\summarization\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr \n",
    "import os \n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text transcription (speech to text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_large_audio_transcription(path):\n",
    "    \"\"\"\n",
    "    Splitting the large audio file into chunks\n",
    "    and apply speech recognition on each of these chunks\n",
    "    \"\"\"\n",
    "    # open the audio file using pydub\n",
    "    sound = AudioSegment.from_wav(path)  \n",
    "    # split audio sound where silence is 700 miliseconds or more and get chunks\n",
    "    chunks = split_on_silence(sound,\n",
    "        # experiment with this value for your target audio file\n",
    "        min_silence_len = 500,\n",
    "        # adjust this per requirement\n",
    "        silence_thresh = sound.dBFS-14,\n",
    "        # keep the silence for 1 second, adjustable as well\n",
    "        keep_silence=500,\n",
    "    )\n",
    "    folder_name = \"audio-chunks\"\n",
    "    # create a directory to store the audio chunks\n",
    "    if not os.path.isdir(folder_name):\n",
    "        os.mkdir(folder_name)\n",
    "    whole_text = \"\"\n",
    "    # process each chunk \n",
    "    for i, audio_chunk in enumerate(chunks, start=1):\n",
    "        # export audio chunk and save it in\n",
    "        # the `folder_name` directory.\n",
    "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
    "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
    "        # recognize the chunk\n",
    "        with sr.AudioFile(chunk_filename) as source:\n",
    "            audio_listened = r.record(source)\n",
    "            # try converting it to text\n",
    "            try:\n",
    "                text = r.recognize_google(audio_listened)\n",
    "            except sr.UnknownValueError as e:\n",
    "                pass\n",
    "                #print(\"Error:\", str(e))\n",
    "            else:\n",
    "                text = f\"{text.capitalize()}. \"\n",
    "                #print(chunk_filename, \":\", text)\n",
    "                whole_text += text\n",
    "    # return the text for all chunks detected\n",
    "    return whole_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was given the task to use the idea of genetic algorithms to be able to solve a problem. The problem that I solved, granted it does not have real world applications, was to get it to figure out a string that the user put in. Since most of my stuff has been done with functional programming, I thought that this would be a good time to use object oriented programming to solve this problem. \n",
      "\n",
      "The main idea of genetic algorithms is to have many entities of something, in this case it would be the random strings, and allow the most ‘fit’ entities to survive and reproduce. Doing over many iterations allows desired traits to be passed over, and hopefully will create an entity that is the most efficient in its task. This imitates natural section in evolution proposed by Charles Darwin.\n",
      "\n",
      "Coding this was split up into two parts, the first with coding the entity object followed by the population object. The entity object containes attributes relating to a single beings such as fitnessLevel, entityString, selectionForBreeding and the mutationRate. While the Population object contain attibutes targetString, topScore, topEntity, the vectors of entityPopulation and the breedingPopulation.\n",
      "\n",
      "The Entity is just a string with the same number of characters as the populations targetString. This ties in with what the fitness function, which is defined as the percentage of characters that are in the correct possition. An example of this would be where the targetString is “Cupcake” and the entity is “JupCake”, the fitnessLevel would be 71%. Something to note is that the function is case sensitive meaning, ‘C’ and ‘c’ are not the same character.\n",
      "\n",
      "The other attributes selectForBreeding and mutationRate are there to decide when a entity is going to reproduce and after reproducting, if there is going to be a mutation of some kind. The functions that handle these ideas will be done with in the population class \n",
      "\n",
      "The The population consists of multiple entities which are stored with in the entity_pop vector. These entities are then selected and put into the breed_pop and then reproducted and then mutated.\n",
      "\n",
      "The selection function gives each entity with in the generation a fitness score, setting the \"fittest\" entity's score as the top_score and its string as top_entity.\n",
      "\n",
      "This is followed by setting each entity's selectForBreeding to either true or false if the entities fitness meets a threshold of 40% of the top entities score. I set it to be like this becuase if none of the entities scored higher then a base threshold the breeding population will be empty. This way there will always be entities that are put into the breeding population.\n",
      "\n",
      "The next step in the process to breed the entities that are the strongest in the generation. We need to first make the population an even number of entities so there isn't just one lone parent left. This is done by removing the lowest scoring enetitiy. Now that there is an even number of entities, parents are entities that adjacent in the vector.\n",
      "\n",
      "The goal of breeding was to be able to keep the correct characters. This was done by cycling through each character of both parents. If a match was found in either parent, that character would end up in the children. If neither parent's character is correct for a given index, the parent's characters would be swapped in the children.\n",
      "\n",
      "From above only the blue values persisted through the breeding with the other characters swapping over in the children. With the children now created, they are put into the \"new\" generation (in code, when breed is called the entity_pop vector is cleared).\n",
      "\n",
      "Since the entity_popwill no longer be the same length as the initial population. New children must be made so that the population size is consistent between generations. Here we take random parents from the breeding population and perform cross-over reproduction. This is where a random index is chosen to slice the parents and the two halves are swapped.\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    text = get_large_audio_transcription(\"AudioFiles/Convo1.wav\")\n",
    "else: \n",
    "    with open(\".\\\\testTexts\\\\GA.txt\", \"r\", encoding=\"utf8\") as file:\n",
    "        text = file.read()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summarization - Text Ranking and RAKE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextRank NLTK\n",
    "#### cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nigel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nigel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workds for filtering\n",
    "def decontracted(phrase):\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "given task use idea genetic algorithms able solve problem.\n",
      "problem solved  granted real world applications  get figure string user put in.\n",
      "since stuff done functional programming  thought would good time use object oriented programming solve problem.\n",
      "main idea genetic algorithms many entities something  case would random strings  allow  fit  entities survive reproduce.\n",
      "many iterations allows desired traits passed over  hopefully create entity efficient task.\n",
      "imitates natural section evolution proposed charles darwin.\n",
      "coding split two parts  first coding entity object followed population object.\n",
      "entity object containes attributes relating single beings fitnesslevel  entitystring  selectionforbreeding mutationrate.\n",
      "population object contain attibutes targetstring  topscore  topentity  vectors entitypopulation breedingpopulation.\n",
      "entity string number characters populations targetstring.\n",
      "ties fitness function  defined percentage characters correct possition.\n",
      "example would targetstring  cupcake  entity  jupcake   fitnesslevel would    .\n",
      "something note function case sensitive meaning   c   c  character.\n",
      "attributes selectforbreeding mutationrate decide entity going reproduce reproducting  going mutation kind.\n",
      "functions handle ideas done population class population consists multiple entities stored entity pop vector.\n",
      "entities selected put breed pop reproducted mutated.\n",
      "selection function gives entity generation fitness score  setting  fittest  entity score top score string top entity.\n",
      "followed setting entity selectforbreeding either true false entities fitness meets threshold     top entities score.\n",
      "set like becuase none entities scored higher base threshold breeding population empty.\n",
      "way always entities put breeding population.\n",
      "next step process breed entities strongest generation.\n",
      "need first make population even number entities one lone parent left.\n",
      "done removing lowest scoring enetitiy.\n",
      "even number entities  parents entities adjacent vector.\n",
      "goal breeding able keep correct characters.\n",
      "done cycling character parents.\n",
      "match found either parent  character would end children.\n",
      "neither parent character correct given index  parent characters would swapped children.\n",
      "blue values persisted breeding characters swapping children.\n",
      "children created  put  new  generation  in code  breed called entity pop vector cleared .\n",
      "since entity popwill longer length initial population.\n",
      "new children must made population size consistent generations.\n",
      "take random parents breeding population perform cross over reproduction.\n",
      "random index chosen slice parents two halves swapped.\n"
     ]
    }
   ],
   "source": [
    "def sentCleaner(text):\n",
    "    stopWords = stopwords.words('english') #set stopwords\n",
    "    temp = []\n",
    "    sent = [s.lower() for s in text] #make things lowercase\n",
    "    sent = [decontracted(s) for s in sent] # decontract words\n",
    "    \n",
    "    return_sent = []\n",
    "    for s in sent:\n",
    "        temp = s.split()\n",
    "        temp = \" \".join([word for word in temp if word not in stopWords])\n",
    "        return_sent.append(temp)\n",
    "    \n",
    "    return_sent = pd.Series(return_sent).str.replace(\"[^a-zA-Z]\",\" \")\n",
    "    return return_sent\n",
    "\n",
    "clean_sentences = sentCleaner(sentences)\n",
    "clean_sentences\n",
    "\n",
    "inTextFormat = False\n",
    "if inTextFormat:\n",
    "    clean_sentences = \". \".join(clean_sentences)\n",
    "\n",
    "    all_occur = [m.start() for m in re.finditer(' . ', clean_sentences)]\n",
    "\n",
    "    temp =\"\"\n",
    "    for idx in range(len(all_occur)):\n",
    "        if(idx == 0):\n",
    "            temp += clean_sentences[0:all_occur[idx]] +\". \"\n",
    "        else:\n",
    "            temp +=clean_sentences[all_occur[idx-1]+3: all_occur[idx]] + \".\"\n",
    "\n",
    "    clean_sentences = temp\n",
    "else:\n",
    "    for i in range(len(clean_sentences)):\n",
    "        temp = clean_sentences[i][:len(clean_sentences[i]) - 1] \n",
    "        temp += \".\"\n",
    "        clean_sentences[i] = temp\n",
    "\n",
    "for i in range(len(clean_sentences)):\n",
    "    print(clean_sentences[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vector representation and ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import networkx as nx\n",
    "from zipfile import ZipFile\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get files and extract them\n",
    "\n",
    "if not os.path.isfile(\"./glove.6B.zip\"):\n",
    "    print(\"file doesnt exists, downloading it now\")\n",
    "    wget.download(\"http://nlp.stanford.edu/data/glove.6B.zip\")\n",
    "    \n",
    "#extract to proper file\n",
    "try:\n",
    "    if len(os.listdir(\"./vectorfile\")) == 0:\n",
    "        with ZipFile(\"glove.6B.zip\", 'r') as zip_ref:\n",
    "            print(\"unzipping\")\n",
    "            zip_ref.extractall(\"vectorfile\")\n",
    "except:\n",
    "    os.mkdir(\"./vectorfile\")\n",
    "    with ZipFile(\"glove.6B.zip\", 'r') as zip_ref:\n",
    "            print(\"unzipping\")\n",
    "            zip_ref.extractall(\"vectorfile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract word vectors\n",
    "word_embeddings = {}\n",
    "f = open('vectorfile/glove.6B.100d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    word_embeddings[word] = coefs\n",
    "f.close()\n",
    "\n",
    "len(word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "given task use idea genetic algorithms able solve problem.\n",
      "problem solved  granted real world applications  get figure string user put in.\n",
      "since stuff done functional programming  thought would good time use object oriented programming solve problem.\n",
      "main idea genetic algorithms many entities something  case would random strings  allow  fit  entities survive reproduce.\n",
      "many iterations allows desired traits passed over  hopefully create entity efficient task.\n",
      "imitates natural section evolution proposed charles darwin.\n",
      "coding split two parts  first coding entity object followed population object.\n",
      "entity object containes attributes relating single beings fitnesslevel  entitystring  selectionforbreeding mutationrate.\n",
      "population object contain attibutes targetstring  topscore  topentity  vectors entitypopulation breedingpopulation.\n",
      "entity string number characters populations targetstring.\n",
      "ties fitness function  defined percentage characters correct possition.\n",
      "example would targetstring  cupcake  entity  jupcake   fitnesslevel would    .\n",
      "something note function case sensitive meaning   c   c  character.\n",
      "attributes selectforbreeding mutationrate decide entity going reproduce reproducting  going mutation kind.\n",
      "functions handle ideas done population class population consists multiple entities stored entity pop vector.\n",
      "entities selected put breed pop reproducted mutated.\n",
      "selection function gives entity generation fitness score  setting  fittest  entity score top score string top entity.\n",
      "followed setting entity selectforbreeding either true false entities fitness meets threshold     top entities score.\n",
      "set like becuase none entities scored higher base threshold breeding population empty.\n",
      "way always entities put breeding population.\n",
      "next step process breed entities strongest generation.\n",
      "need first make population even number entities one lone parent left.\n",
      "done removing lowest scoring enetitiy.\n",
      "even number entities  parents entities adjacent vector.\n",
      "goal breeding able keep correct characters.\n",
      "done cycling character parents.\n",
      "match found either parent  character would end children.\n",
      "neither parent character correct given index  parent characters would swapped children.\n",
      "blue values persisted breeding characters swapping children.\n",
      "children created  put  new  generation  in code  breed called entity pop vector cleared .\n",
      "since entity popwill longer length initial population.\n",
      "new children must made population size consistent generations.\n",
      "take random parents breeding population perform cross over reproduction.\n",
      "random index chosen slice parents two halves swapped.\n"
     ]
    }
   ],
   "source": [
    "sentence_vectors = []\n",
    "for i in clean_sentences:\n",
    "    print(i)\n",
    "    if len(i) != 0:\n",
    "        v = sum([word_embeddings.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split())+0.001)\n",
    "    else:\n",
    "        v = np.zeros((100,))\n",
    "    sentence_vectors.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find similarities\n",
    "sim_mat = np.zeros([len(sentences), len(sentences)])\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    for j in range(len(sentences)):\n",
    "        if i != j:\n",
    "            sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,100), sentence_vectors[j].reshape(1,100))[0,0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = nx.from_numpy_array(sim_mat)\n",
    "scores = nx.pagerank(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We need to first make the population an even number of entities so there isn't just one lone parent left.\n",
      "The main idea of genetic algorithms is to have many entities of something, in this case it would be the random strings, and allow the most ‘fit’ entities to survive and reproduce.\n",
      "With the children now created, they are put into the \"new\" generation (in code, when breed is called the entity_pop vector is cleared).\n",
      "Since most of my stuff has been done with functional programming, I thought that this would be a good time to use object oriented programming to solve this problem.\n",
      "New children must be made so that the population size is consistent between generations.\n",
      "Doing over many iterations allows desired traits to be passed over, and hopefully will create an entity that is the most efficient in its task.\n",
      "The problem that I solved, granted it does not have real world applications, was to get it to figure out a string that the user put in.\n"
     ]
    }
   ],
   "source": [
    "ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n",
    "#display to 10%\n",
    "for i in range(ceil(len(ranked_sentences)*0.2)):\n",
    "    print(ranked_sentences[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAKE (rapid automatic keyword extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rake_nltk import Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'help figure best place buy used car. always purchase used cars advertisement paper actually many options. else look car look internet autotrader best cars listed sold locally. would best wanted actually go see lot used cars sale. best place carmax large used car lot. know card access. many look internet phone book one closest you. listings college bulletin board actually bad way go especially near end semester student moving away.'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\n",
    "if type(clean_sentences) != str:\n",
    "    for i in range(len(clean_sentences)):\n",
    "        if i == 0:\n",
    "            text = clean_sentences[i]\n",
    "        else:\n",
    "            text += \" \" + clean_sentences[i]\n",
    "        \n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "rake_obj = Rake()\n",
    "rake_obj.extract_keywords_from_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: listings college bulletin board actually bad way go especially near end semester student moving away\n",
      "score: 218.83333333333331\n",
      "\n",
      "\n",
      "text: else look car look internet autotrader best cars listed sold locally\n",
      "score: 110.41666666666666\n",
      "\n",
      "\n",
      "text: would best wanted actually go see lot used cars sale\n",
      "score: 99.33333333333334\n",
      "\n",
      "\n",
      "text: always purchase used cars advertisement paper actually many options\n",
      "score: 82.58333333333333\n",
      "\n",
      "\n",
      "text: best place carmax large used car lot\n",
      "score: 54.833333333333336\n",
      "\n",
      "\n",
      "text: many look internet phone book one closest\n",
      "score: 54.666666666666664\n",
      "\n",
      "\n",
      "text: help figure best place buy used car\n",
      "score: 53.333333333333336\n",
      "\n",
      "\n",
      "text: know card access\n",
      "score: 9.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = rake_obj.get_ranked_phrases_with_scores()\n",
    "\n",
    "for item in scores:\n",
    "    print(\"text: {1}\\nscore: {0}\\n\\n\".format(item[0], item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(218.83333333333331,\n",
       "  'listings college bulletin board actually bad way go especially near end semester student moving away'),\n",
       " (110.41666666666666,\n",
       "  'else look car look internet autotrader best cars listed sold locally'),\n",
       " (99.33333333333334, 'would best wanted actually go see lot used cars sale'),\n",
       " (82.58333333333333,\n",
       "  'always purchase used cars advertisement paper actually many options'),\n",
       " (54.833333333333336, 'best place carmax large used car lot'),\n",
       " (54.666666666666664, 'many look internet phone book one closest'),\n",
       " (53.333333333333336, 'help figure best place buy used car'),\n",
       " (9.0, 'know card access')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_rake_obj = Rake(min_length = 3, max_length=15)\n",
    "adv_rake_obj.extract_keywords_from_text(text)\n",
    "adv_rake_obj.get_ranked_phrases_with_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
